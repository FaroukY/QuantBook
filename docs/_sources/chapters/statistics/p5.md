# Problem 5: Attack of the Coefficients

```{note}
You should attempt [](p4.md) before attempting this problem. 
```

Suppose that you have two matrices of regressors $X_1$ and $X_2$ where:

- $X_1$ is $N \times k$
- $X_2$ is $N \times (f - k)$

You fit a multiple regression model for a target variable $Y$ onto $X_1$, obtaining residuals $e$, and a QR decomposition of the matrix $X_1$.

---

Derive an efficient procedure to compute the new coefficients of the regression using all variables in $X_1$ plus the variable from $X_2$ you want to add based on [](p4.md).

````{dropdown} Click to show solution

**Extended model and notation**  
Let $\beta \in \mathbb{R}^k$ be the OLS coefficient for the current fit $Y = X_1 \beta + e$, so $e = Y - X_1 \beta$. From part (a), $x_j \in \mathbb{R}^N$ is the predictor chosen to add, and $z_j = (I - Q_1 Q_1^\top) x_j$. We now fit:

$$
Y = X_1 \, \beta_{\mathrm{new}} + \gamma_j \, x_j,
$$

seeking $\beta_{\mathrm{new}} \in \mathbb{R}^k$ and $\gamma_j \in \mathbb{R}$.

---

**Exact formula for $\gamma_j$**  
As shown in part (a):

$$
\gamma_j = \frac{e^\top z_j}{\|z_j\|^2}
= \frac{e^\top x_j - e^\top Q_1 Q_1^\top x_j}{\|x_j\|^2 - \|Q_1^\top x_j\|^2}
= \frac{e^\top x_j}{\|x_j\|^2 - \|Q_1^\top x_j\|^2}.
$$

---

**Update for $\beta_{\mathrm{new}}$**  
Holding $\gamma_j$ fixed, the normal equations for $\beta_{\mathrm{new}}$ give:

$$
\beta_{\mathrm{new}} = (X_1^\top X_1)^{-1} X_1^\top (Y - \gamma_j x_j)
= \beta - \gamma_j (X_1^\top X_1)^{-1} X_1^\top x_j.
$$

Define the vector:

$$
d = (X_1^\top X_1)^{-1} X_1^\top x_j,
$$

yielding the concise update:

$$
\boxed{ \beta_{\mathrm{new}} = \beta - \gamma_j \, d. }
$$

---

**Efficient computation of $d$ via the QR factorization**  
Since $X_1 = Q_1 R_1$ with $Q_1^\top Q_1 = I$, we have:

$$
X_1^\top X_1 = R_1^\top R_1,
\quad
X_1^\top x_j = R_1^\top (Q_1^\top x_j).
$$

Hence:

$$
d = (R_1^\top R_1)^{-1} R_1^\top (Q_1^\top x_j)
= R_1^{-1} Q_1^\top x_j.
$$

Equivalently, $d$ is the unique solution of the upper-triangular system:

$$
R_1 d = Q_1^\top x_j,
$$

which can be solved in $O(k^2)$ time by backward substitution.

---

**Algorithmic Implementation**  
Let $x_j$ be the best column from part (a).

1. Compute:

   $$
   \gamma_j = \frac{e^\top x_j}{\|x_j\|^2 - \|Q_1^\top x_j\|^2}.
   $$

2. Solve the triangular system $R_1 d = Q_1^\top x_j$ for $d \in \mathbb{R}^k$.

3. Update:

   $$
   \beta_{\mathrm{new}} = \beta - \gamma_j \, d.
   $$

4. The augmented parameter vector is:

   $$
   \begin{bmatrix} \beta_{\mathrm{new}} \\ \gamma_j \end{bmatrix} \in \mathbb{R}^{k+1}.
   $$

````
